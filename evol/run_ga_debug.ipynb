{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec3cbb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import pyranges as pr\n",
    "from collections import Counter\n",
    "from deap import base, creator, tools\n",
    "import os\n",
    "import multiprocessing\n",
    "from multiprocessing import Manager\n",
    "import uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0325c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/tangfuchou_pkuhpc/tangfuchou_coe/jiangzh/software/anaconda3/envs/get/lib/python3.12/site-packages/paramiko/pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "/gpfs1/tangfuchou_pkuhpc/tangfuchou_coe/jiangzh/software/anaconda3/envs/get/lib/python3.12/site-packages/paramiko/transport.py:253: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n",
      "/gpfs1/tangfuchou_pkuhpc/tangfuchou_coe/jiangzh/software/anaconda3/envs/get/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.chdir('/gpfs1/tangfuchou_pkuhpc/tangfuchou_coe/jiangzh/cellTransformer/code/evol/')\n",
    "from pred import CellTransformer, load_msgpack, map_guide_to_peaks\n",
    "\n",
    "os.chdir('/gpfs1/tangfuchou_pkuhpc/tangfuchou_coe/jiangzh/cellTransformer/GET/')\n",
    "\n",
    "# =========================================\n",
    "# Configuration\n",
    "# =========================================\n",
    "CONFIG = {\n",
    "    \"population_size\": 50,\n",
    "    \"num_generations\": 50,\n",
    "    \"crossover_prob\": 0.7,\n",
    "    \"mutation_prob\": 0.3,\n",
    "    \"tournament_size\": 5,\n",
    "    \"set_size\": 3\n",
    "}\n",
    "\n",
    "KMER_CONFIG = {\n",
    "    \"max_global_hits\": 1e4,\n",
    "    \"min_local_hits\": 3,\n",
    "    \"min_effective_hits\": 1\n",
    "}\n",
    "\n",
    "# Global references\n",
    "kmer_to_peak = None\n",
    "roi = None\n",
    "fitness_cache = None\n",
    "threads = 8  # Default number of threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a221e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =========================================\n",
    "# Data loading\n",
    "# =========================================\n",
    "def init_worker(kmer_data, roi_data, cache_dict):\n",
    "    global kmer_to_peak, roi, fitness_cache\n",
    "    kmer_to_peak = kmer_data\n",
    "    roi = roi_data\n",
    "    fitness_cache = cache_dict\n",
    "\n",
    "def load_kmer_index():\n",
    "    return load_msgpack(\"./data/index/hg38_CATlas_cCREs.9mer.kmer_to_peak_freq.msgpack\")\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load ROI and k-mer datasets for the GA search.\"\"\"\n",
    "    try:\n",
    "        roi = pr.PyRanges(\n",
    "            chromosomes=[\"chr19\"],\n",
    "            starts=[int(55115750 - 5e5)],\n",
    "            ends=[int(55115750 + 5e5)]\n",
    "        )\n",
    "        with open('./data/intervention/hg38_CATlas_cCREs.9mer.kmer_cov_by_peak.pkl', 'rb') as f:\n",
    "            kmer_cov = pickle.load(f)\n",
    "\n",
    "        with open('./data/intervention/AAVS1_1Mb_9mer_HEK293T_novel.pkl', 'rb') as f:\n",
    "            roi_kmer = pickle.load(f)\n",
    "\n",
    "        # Filter out extremely common kmers\n",
    "        kmer_cov_flt = {k: v for k, v in kmer_cov.items() if v <= KMER_CONFIG[\"max_global_hits\"]}\n",
    "        roi_kmer_counts = Counter(k for k in roi_kmer if k in kmer_cov_flt)\n",
    "        roi_kmer_list = [k for k, count in roi_kmer_counts.items() if count >= KMER_CONFIG[\"min_local_hits\"]]\n",
    "\n",
    "        if not roi_kmer_list:\n",
    "            raise ValueError(\"No valid k-mers found after filtering\")\n",
    "\n",
    "        print(f\"Available k-mers: {len(roi_kmer_list)}\")\n",
    "        return roi, roi_kmer_list\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# Helper: fix duplicates\n",
    "# =========================================\n",
    "def fix_duplicates(individual, kmer_list):\n",
    "    \"\"\"Ensure no duplicate kmers in an individual.\"\"\"\n",
    "    seen = set()\n",
    "    for i in range(len(individual)):\n",
    "        if individual[i] in seen:\n",
    "            choices = [k for k in kmer_list if k not in seen]\n",
    "            individual[i] = random.choice(choices)\n",
    "        seen.add(individual[i])\n",
    "    return individual\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# Fitness function with caching\n",
    "# =========================================\n",
    "def fitness(individual):\n",
    "    \"\"\"Evaluate individual fitness using CellTransformer, with caching.\"\"\"\n",
    "\n",
    "    key = tuple(individual)\n",
    "    if key in fitness_cache:\n",
    "        return (fitness_cache[key],)\n",
    "\n",
    "    peak_hits = map_guide_to_peaks(\n",
    "        individual, \n",
    "        kmer_to_peak, \n",
    "        hit_threshold=KMER_CONFIG[\"min_effective_hits\"]\n",
    "    )\n",
    "\n",
    "    run_id = uuid.uuid4() \n",
    "\n",
    "    ct = CellTransformer(\n",
    "        guide_list=list(individual),\n",
    "        peak_hits=peak_hits,\n",
    "        target_gene=[\"GFP\"],\n",
    "        output_dir=\"./data/get_tmp/\",\n",
    "        celltype=\"HEK293T\",\n",
    "        insert_transgene=True,\n",
    "        prediction_scope=roi,\n",
    "        run_id=run_id,\n",
    "        motif_bed=\"../resource/hg38.archetype_motifs.v1.0.bed.gz\",\n",
    "        zarr_path=\"./data/zarr/HEK293T_hPGK1_AAVS1.zarr\",\n",
    "    )\n",
    "\n",
    "    score = ct.predict()    \n",
    "\n",
    "    fitness_cache[key] = score\n",
    "    return (score,)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# Custom mutation\n",
    "# =========================================\n",
    "def custom_mutation(individual, indpb, kmer_list):\n",
    "    \"\"\"Randomly replace k-mers in the individual with probability indpb.\"\"\"\n",
    "    for i in range(len(individual)):\n",
    "        if random.random() < indpb:\n",
    "            new_kmer = random.choice(kmer_list)\n",
    "            while new_kmer in individual:  # avoid duplicates\n",
    "                new_kmer = random.choice(kmer_list)\n",
    "            individual[i] = new_kmer\n",
    "    return individual,\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# Main GA procedure\n",
    "# =========================================\n",
    "def main():\n",
    "    global kmer_to_peak, roi, fitness_cache, threads\n",
    "\n",
    "    # Load data\n",
    "    kmer_to_peak = load_kmer_index()\n",
    "    roi, roi_kmer_list = load_data()\n",
    "\n",
    "    manager = Manager()\n",
    "    fitness_cache = manager.dict()\n",
    "\n",
    "    # DEAP setup\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_kmer\", lambda: random.choice(roi_kmer_list))\n",
    "    toolbox.register(\"individual\", tools.initIterate, creator.Individual,\n",
    "                     lambda: random.sample(roi_kmer_list, CONFIG[\"set_size\"]))\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    toolbox.register(\"mate\", tools.cxUniform, indpb=0.5)\n",
    "    toolbox.register(\"mutate\", custom_mutation, kmer_list=roi_kmer_list, indpb=CONFIG[\"mutation_prob\"])\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=CONFIG[\"tournament_size\"])\n",
    "    toolbox.register(\"evaluate\", fitness)\n",
    "\n",
    "    # Enable multiprocessing for faster evaluation\n",
    "    pool = multiprocessing.Pool(\n",
    "        processes=threads,\n",
    "        initializer=init_worker,\n",
    "        initargs=(kmer_to_peak, roi, fitness_cache)\n",
    "    )\n",
    "    toolbox.register(\"map\", pool.map)\n",
    "\n",
    "    # Initialize population & statistics\n",
    "    pop = toolbox.population(n=CONFIG[\"population_size\"])\n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", lambda fits: sum(f[0] for f in fits) / len(fits))\n",
    "    stats.register(\"max\", lambda fits: max(f[0] for f in fits))\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = [\"gen\", \"best_fitness\", \"avg_fitness\"]\n",
    "\n",
    "    # Initialize CSV file for storing individual data\n",
    "    output_file = f\"ga_individuals_{uuid.uuid4()}.csv\"\n",
    "    pd.DataFrame(columns=[\"Generation\", \"Individual\", \"Fitness\"]) \\\n",
    "        .to_csv(output_file, index=False)\n",
    "\n",
    "    # Evolutionary loop\n",
    "    for gen in range(CONFIG[\"num_generations\"]):\n",
    "        offspring = toolbox.select(pop, len(pop))\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "        # Crossover\n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < CONFIG[\"crossover_prob\"]:\n",
    "                toolbox.mate(child1, child2)\n",
    "                fix_duplicates(child1, roi_kmer_list)\n",
    "                fix_duplicates(child2, roi_kmer_list)\n",
    "                del child1.fitness.values\n",
    "                del child2.fitness.values\n",
    "\n",
    "        # Mutation\n",
    "        for mutant in offspring:\n",
    "            if random.random() < CONFIG[\"mutation_prob\"]:\n",
    "                toolbox.mutate(mutant)\n",
    "                fix_duplicates(mutant, roi_kmer_list)\n",
    "                del mutant.fitness.values\n",
    "\n",
    "        # Fitness evaluation\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # Save individual data to CSV using pandas\n",
    "        df = pd.DataFrame([\n",
    "            [gen, str(ind), ind.fitness.values[0]]\n",
    "            for ind in offspring\n",
    "        ], columns=[\"generation\", \"individual\", \"fitness\"])\n",
    "        df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "\n",
    "        pop[:] = offspring\n",
    "        hof.update(pop)\n",
    "\n",
    "        # Logging\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=gen, best_fitness=hof[0].fitness.values[0], avg_fitness=record[\"avg\"])\n",
    "        print(logbook.stream)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print(f\"Individual data saved to {output_file}\")\n",
    "    return hof[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b66bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available k-mers: 655\n"
     ]
    }
   ],
   "source": [
    "individual=['GGCAGGGGG', 'GAGGGAGGA', 'AGCAGCAGC']\n",
    "roi, roi_kmer_list = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5393678e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./data/index/hg38_CATlas_cCREs.9mer.kmer_to_peak_freq.msgpack...\n"
     ]
    }
   ],
   "source": [
    "global kmer_to_peak, roi, fitness_cache, threads\n",
    "\n",
    "# Load data\n",
    "kmer_to_peak = load_kmer_index()\n",
    "\n",
    "peak_hits = map_guide_to_peaks(\n",
    "    individual, \n",
    "    kmer_to_peak, \n",
    "    hit_threshold=KMER_CONFIG[\"min_effective_hits\"]\n",
    ")\n",
    "\n",
    "# save hits in pickle for test\n",
    "with open(\"./data/get_tmp/peak_hits.pkl\", \"wb\") as f:\n",
    "    pickle.dump(peak_hits, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "723a3f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction for HEK293T with run ID 82fa1969-ef31-4313-a16b-f4c73c054850...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W::hts_idx_load3] The index file is older than the data file: ../resource/hg38.archetype_motifs.v1.0.bed.gz.tbi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 282 motifs from main zarr.\n",
      "Written increment 'activation_82fa1969-ef31-4313-a16b-f4c73c054850' to ./data/zarr/HEK293T_hPGK1_AAVS1.zarr/added/activation_82fa1969-ef31-4313-a16b-f4c73c054850 with shape (24, 282)\n",
      "TSS and dummy expression annotated for 'added/activation_82fa1969-ef31-4313-a16b-f4c73c054850' with celltype 'HEK293T'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/tangfuchou_pkuhpc/tangfuchou_coe/jiangzh/software/anaconda3/envs/get/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ckpt from ./data/checkpoints/finetune_fetal_adult_leaveout_astrocyte.checkpoint-best.pth\n",
      "Load state_dict by model_key = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs1/tangfuchou_pkuhpc/tangfuchou_coe/jiangzh/software/anaconda3/envs/get/lib/python3.12/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /gpfs1/tangfuchou_pkuhpc/tangfuchou_coe/jiangzh/soft ...\n",
      "/gpfs1/tangfuchou_pkuhpc/tangfuchou_coe/jiangzh/software/anaconda3/envs/get/lib/python3.12/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of peaks: 101589\n",
      "Total peaks after adding: 101613\n",
      "No 'deleted' group found in Zarr file. No peaks removed.\n",
      "Loaded region motifs for celltype HEK293T: 101613 peaks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 41.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: []\n",
      "Input chromosomes: ['chr1', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr2', 'chr20', 'chr21', 'chr22', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chrX']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/gpfs1/tangfuchou_pkuhpc/tangfuchou_coe/jiangzh/software/anaconda3/envs/get/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:362: The dirpath has changed from '/mnt/e/SHARE/cellTransformer/GET/data/get_output/HEK293T/regionEmb_head_finetune_binary/checkpoints' to '/gpfs1/tangfuchou_pkuhpc/tangfuchou_coe/jiangzh/cellTransformer/GET/data/get_tmp/HEK293T/intervention_82fa1969-ef31-4313-a16b-f4c73c054850/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "/gpfs1/tangfuchou_pkuhpc/tangfuchou_coe/jiangzh/software/anaconda3/envs/get/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c427f02a754c47acce7c5f54c19925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6332805156707764\n"
     ]
    }
   ],
   "source": [
    "# load peak hits from pickle\n",
    "with open(\"./data/get_tmp/peak_hits.pkl\", \"rb\") as f:\n",
    "    peak_hits = pickle.load(f)\n",
    "\n",
    "run_id = uuid.uuid4() \n",
    "\n",
    "ct = CellTransformer(\n",
    "    guide_list=list(individual),\n",
    "    peak_hits=peak_hits,\n",
    "    target_gene=[\"GFP\"],\n",
    "    output_dir=\"./data/get_tmp/\",\n",
    "    celltype=\"HEK293T\",\n",
    "    insert_transgene=True,\n",
    "    prediction_scope=roi,\n",
    "    run_id=run_id,\n",
    "    motif_bed=\"../resource/hg38.archetype_motifs.v1.0.bed.gz\",\n",
    "    zarr_path=\"./data/zarr/HEK293T_hPGK1_AAVS1.zarr\",\n",
    "    num_region_per_sample=202 # debug\n",
    ")\n",
    "\n",
    "score = ct.predict()  \n",
    "\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
